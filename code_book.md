##**code_book.md**

The code is sourced and to may be used non-commercially with the Human Activity Recognition Using Smartphones Dataset (Version 1) data, as referenced in the README.md file--attached within this Repo.

The experiments have been carried out with a group of 30 volunteers [*NOTE: SUBJECT*] within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING [*NOTE: ACTIVITY*]) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data.         
**Source: Smartlab - Non Linear Complex Systems Laboratory**


The sensor signals have been filtered down to means and standard deviations for both *ACTIVITY* and *SUBJECT* (see above).


###Variable names in tidy_data.txt include (among both mean and stdev averages w/respective X,Y,Z axes):

-activtySubject

-tBodyAcc

-tGravityAcc

-tBodyAccJerk

-tBodyGyro

-tBodyGyroJerk

-tBodyAccMag

-tBodyAccJerkMag

-tBodyGyroMag

-tBodyGyroJerkMag

-fBodyAcc

-fBodyAcc

-fBodyAccJerk

-fBodyAccJerk

-fBodyGyro

-fBodyGyro

-fBodyAccMag

-fBodyBodyAccJerkMag 

-fBodyBodyGyroMag

-fBodyBodyGyroJerkMag



Source:
[1] Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. International Workshop of Ambient Assisted Living (IWAAL 2012). Vitoria-Gasteiz, Spain. Dec 2012

